{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell to install the required libraries"
      ],
      "metadata": {
        "id": "HWYwb5PTMDCw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pSSXBF4L2IW"
      },
      "outputs": [],
      "source": [
        "pip install transformers torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell and upload the audio file when prompted"
      ],
      "metadata": {
        "id": "C-2r_55QMOnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Display the uploaded file(s)\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"Uploaded file: {filename}\")\n",
        "    file_path = filename\n"
      ],
      "metadata": {
        "id": "myDEmTH_L8CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run this cell and wait for all chunks to be trascribed. The final output will be shown after all chunks are done.\n",
        "\n",
        "## Whisper Large v2 Supported Languages and Codes\n",
        "\n",
        "Below is the full list of languages supported by Whisper Large v2 with their corresponding code parameters:\n",
        "\n",
        "| Language              | Code  | Language            | Code  |\n",
        "|-----------------------|-------|---------------------|-------|\n",
        "| Afrikaans             | `af`  | Albanian            | `sq`  |\n",
        "| Amharic               | `am`  | Arabic              | `ar`  |\n",
        "| Armenian              | `hy`  | Assamese            | `as`  |\n",
        "| Azerbaijani           | `az`  | Bashkir             | `ba`  |\n",
        "| Basque                | `eu`  | Belarusian          | `be`  |\n",
        "| Bengali               | `bn`  | Bosnian             | `bs`  |\n",
        "| Bulgarian             | `bg`  | Burmese             | `my`  |\n",
        "| Catalan               | `ca`  | Chinese (Simplified)| `zh`  |\n",
        "| Chinese (Traditional) | `zh-tw`| Croatian           | `hr`  |\n",
        "| Czech                 | `cs`  | Danish              | `da`  |\n",
        "| Dutch                 | `nl`  | English             | `en`  |\n",
        "| Esperanto             | `eo`  | Estonian            | `et`  |\n",
        "| Finnish               | `fi`  | French              | `fr`  |\n",
        "| Galician              | `gl`  | Georgian            | `ka`  |\n",
        "| German                | `de`  | Greek               | `el`  |\n",
        "| Gujarati              | `gu`  | Hausa               | `ha`  |\n",
        "| Hebrew                | `he`  | Hindi               | `hi`  |\n",
        "| Hungarian             | `hu`  | Icelandic           | `is`  |\n",
        "| Indonesian            | `id`  | Italian             | `it`  |\n",
        "| Japanese              | `ja`  | Javanese            | `jv`  |\n",
        "| Kannada               | `kn`  | Kazakh              | `kk`  |\n",
        "| Khmer                 | `km`  | Korean              | `ko`  |\n",
        "| Lao                   | `lo`  | Latvian             | `lv`  |\n",
        "| Lithuanian            | `lt`  | Macedonian          | `mk`  |\n",
        "| Malagasy              | `mg`  | Malay               | `ms`  |\n",
        "| Malayalam             | `ml`  | Maltese             | `mt`  |\n",
        "| Maori                 | `mi`  | Marathi             | `mr`  |\n",
        "| Mongolian             | `mn`  | Nepali              | `ne`  |\n",
        "| Norwegian             | `no`  | Oriya (Odia)        | `or`  |\n",
        "| Pashto                | `ps`  | Persian (Farsi)     | `fa`  |\n",
        "| Polish                | `pl`  | Portuguese          | `pt`  |\n",
        "| Punjabi               | `pa`  | Romanian            | `ro`  |\n",
        "| Russian               | `ru`  | Serbian             | `sr`  |\n",
        "| Sinhala               | `si`  | Slovak              | `sk`  |\n",
        "| Slovenian             | `sl`  | Somali              | `so`  |\n",
        "| Spanish               | `es`  | Sundanese           | `su`  |\n",
        "| Swahili               | `sw`  | Swedish             | `sv`  |\n",
        "| Tagalog               | `tl`  | Tamil               | `ta`  |\n",
        "| Tatar                 | `tt`  | Telugu              | `te`  |\n",
        "| Thai                  | `th`  | Turkish             | `tr`  |\n",
        "| Ukrainian             | `uk`  | Urdu                | `ur`  |\n",
        "| Uzbek                 | `uz`  | Vietnamese          | `vi`  |\n",
        "| Welsh                 | `cy`  | Yiddish             | `yi`  |\n",
        "| Yoruba                | `yo`  | Zulu                | `zu`  |\n",
        "\n",
        "You can use the corresponding code for each language in your Whisper configuration to set the desired transcription language.\n",
        "\n",
        "Hereâ€™s how you can modify the code to replace the language in a specific line using GitHub Markdown:\n",
        "\n",
        "```markdown\n",
        "# How to Modify the Language in Code\n",
        "\n",
        "Below is the Python code snippet to change the language in `forced_decoder_ids`:\n",
        "\n",
        "```python\n",
        "# Example: Setting the decoder prompt for a specific language and task\n",
        "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"ta\", task=\"translate\")\n",
        "```\n",
        "\n",
        "### Instructions to Change the Language:\n",
        "1. Locate the line in your code:\n",
        "   ```python\n",
        "   forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"ta\", task=\"translate\")\n",
        "   ```\n",
        "2. Replace the `\"ta\"` (Tamil) in the `language` parameter with the desired language code. For example, to set the language to Spanish (`es`):\n",
        "   ```python\n",
        "   forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"es\", task=\"translate\")\n",
        "   ```\n",
        "\n",
        "\n",
        "3. Run the cell to use the updated language.\n",
        "\n"
      ],
      "metadata": {
        "id": "YlqMV36nMWkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fimport torch\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torchaudio\n",
        "\n",
        "# Load Whisper processor and large-v2 model\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")\n",
        "\n",
        "# Ensure the model is on the appropriate device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Function to preprocess MP3 audio file\n",
        "def preprocess_audio(file_path, sampling_rate=16000):\n",
        "    # Load the audio file\n",
        "    audio, sr = torchaudio.load(file_path)\n",
        "    # Resample to 16kHz if necessary\n",
        "    if sr != sampling_rate:\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=sampling_rate)\n",
        "        audio = resampler(audio)\n",
        "    return audio.squeeze(0)  # Remove channel dimension if stereo\n",
        "\n",
        "# Function to split long audio into chunks\n",
        "def split_audio(audio, chunk_duration, sampling_rate):\n",
        "    num_samples_per_chunk = chunk_duration * sampling_rate\n",
        "    return [audio[i:i + num_samples_per_chunk] for i in range(0, len(audio), num_samples_per_chunk)]\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess the audio\n",
        "audio_tensor = preprocess_audio(file_path)\n",
        "\n",
        "# Split the audio into smaller chunks (30 seconds each)\n",
        "chunk_duration = 30  # Duration of each chunk in seconds\n",
        "chunks = split_audio(audio_tensor, chunk_duration, sampling_rate=16000)\n",
        "\n",
        "# Transcribe each chunk and concatenate results\n",
        "transcriptions = []\n",
        "for i, chunk in enumerate(chunks):\n",
        "    input_features = processor(chunk, sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n",
        "    forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"ta\", task=\"translate\")     #change language here\n",
        "    generated_ids = model.generate(\n",
        "        input_features,\n",
        "        forced_decoder_ids=forced_decoder_ids,\n",
        "        max_new_tokens=444,  # Allow enough tokens for longer transcription\n",
        "    )\n",
        "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    transcriptions.append(transcription)\n",
        "    print(f\"Chunk {i + 1}/{len(chunks)} transcribed.\")\n",
        "\n",
        "# Combine all chunks into the final transcription\n",
        "full_transcription = \" \".join(transcriptions)\n",
        "print(\"\\nFull Transcription:\\n\", full_transcription)\n"
      ],
      "metadata": {
        "id": "BS5NohLEL-Pp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}